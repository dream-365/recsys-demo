{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ef6cc4-3d5f-4f33-ad33-b3f13a558b83",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3514389c-65fb-4e3c-9ed4-85c91d1749ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'emb/item2vecEmb.csv'\n",
    "\n",
    "# 创建一个空字典来存储item_id和相应的向量\n",
    "item_embeddings = {}\n",
    "\n",
    "# 打开文件进行读取\n",
    "with open(file_path, 'r') as file:\n",
    "    # 按行读取数据\n",
    "    for line in file:\n",
    "        # 移除行尾的换行符和额外的空格，并按\":\"进行分割\n",
    "        item_id, vector_str = line.strip().split(':')\n",
    "\n",
    "        # 将字符串形式的向量转换为浮点数列表\n",
    "        vector = [float(x) for x in vector_str.split()]\n",
    "\n",
    "        # 将item_id和向量添加到字典中\n",
    "        item_embeddings[item_id] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a035f9-b7b6-404c-9120-e0cb354bc7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 item IDs and their cosine similarity scores:\n",
      "Item ID: 508, Cosine Similarity: 0.7323549857913757\n",
      "Item ID: 224, Cosine Similarity: 0.7181236844980872\n",
      "Item ID: 337, Cosine Similarity: 0.6937498059356555\n",
      "Item ID: 45, Cosine Similarity: 0.6873704877203618\n",
      "Item ID: 235, Cosine Similarity: 0.679446914216761\n",
      "Item ID: 342, Cosine Similarity: 0.6739160779183327\n",
      "Item ID: 237, Cosine Similarity: 0.6520614285074958\n",
      "Item ID: 193, Cosine Similarity: 0.6481302505611553\n",
      "Item ID: 509, Cosine Similarity: 0.6421518506272028\n",
      "Item ID: 230, Cosine Similarity: 0.6385112464831563\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "top_n = 10  # 找到余弦相似度最高的top_n个项目\n",
    "\n",
    "# 假设user_vector是已知的用户向量，假设item_embeddings是已从文件中读取的字典\n",
    "user_vector = np.array([0.1, 0.3, 0.5, 0.1, 0.3, 0.5, 0.1, 0.3, 0.5, 0.1])  # 示例用户向量\n",
    "embedding_matrix = np.array(list(item_embeddings.values()))\n",
    "item_ids = list(item_embeddings.keys())\n",
    "\n",
    "# 确认用户向量和项目向量的维度匹配\n",
    "assert user_vector.size == embedding_matrix.shape[1]\n",
    "\n",
    "# 计算用户向量与所有项目向量的点积\n",
    "dot_product = np.dot(embedding_matrix, user_vector)\n",
    "\n",
    "# 计算用户向量和所有项目向量的模长\n",
    "user_vector_length = np.linalg.norm(user_vector)\n",
    "item_vector_lengths = np.linalg.norm(embedding_matrix, axis=1)\n",
    "\n",
    "# 计算余弦相似度\n",
    "cosine_similarity = dot_product / (user_vector_length * item_vector_lengths)\n",
    "\n",
    "# 获取相似度最高的前top_n个项目的索引\n",
    "top_n_indices = np.argsort(-cosine_similarity)[:top_n]\n",
    "# 获取对应的余弦相似度得分\n",
    "top_n_cosine_similarity_scores = cosine_similarity[top_n_indices]\n",
    "\n",
    "# 根据索引获取对应的item_id\n",
    "top_n_item_ids = [item_ids[i] for i in top_n_indices]\n",
    "\n",
    "# 打印Top n的item_ids和相应的余弦相似度\n",
    "print(f\"Top {top_n} item IDs and their cosine similarity scores:\")\n",
    "for idx, item_id in enumerate(top_n_item_ids):\n",
    "    print(f\"Item ID: {item_id}, Cosine Similarity: {top_n_cosine_similarity_scores[idx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8259014-2334-4851-89d3-8494b7cb075b",
   "metadata": {},
   "source": [
    "### NeuralCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c6d56-91e8-47ac-ac5f-2b9d7d366c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saved_model_path = \"model/NeuralCF\"\n",
    "\n",
    "# 加载模型\n",
    "model = tf.keras.models.load_model(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
